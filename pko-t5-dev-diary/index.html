<!DOCTYPE html>
<html lang="ko" class="no-js">
    <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    
    

    
    

    
    

    
    

    <title>pko-T5 모델 개발기 | PAUST TechBlog</title>
    <meta name="description" content="파우스트에서 한국어 코퍼스를 활용하여 대규모 데이터셋과 pre-trained 모델로써 T5를 만들었던 개발 경험과 노하우를 공유합니다.">
    
        <meta name="keywords" content="modeling, shaple">
    

    <!-- Social: Twitter -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="pko-T5 모델 개발기 | PAUST TechBlog">
    <meta name="twitter:description" content="파우스트에서 한국어 코퍼스를 활용하여 대규모 데이터셋과 pre-trained 모델로써 T5를 만들었던 개발 경험과 노하우를 공유합니다.">

    
        <meta property="twitter:image" content="https://s.abcnews.com/images/Technology/AP_black_hole_kab_150226_16x9_992.jpg">
    
    
    

    <!-- Social: Facebook / Open Graph -->
    <meta property="og:url" content="/pko-t5-dev-diary/">
    <meta property="og:title" content="pko-T5 모델 개발기 | PAUST TechBlog">
    <meta property="og:image" content="https://s.abcnews.com/images/Technology/AP_black_hole_kab_150226_16x9_992.jpg">
    <meta property="og:description" content="파우스트에서 한국어 코퍼스를 활용하여 대규모 데이터셋과 pre-trained 모델로써 T5를 만들었던 개발 경험과 노하우를 공유합니다.">
    <meta property="og:site_name" content="PAUST TechBlog | Artificial Intelligent Tech Blog by PAUST">

    <!-- Favicon -->
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />

    <!-- Android Lolipop Theme Color -->
    <meta name="theme-color" content="#141414">

    <!-- Fonts -->
    <link href="https://fonts.googleapis.com/css?family=Titillium+Web:300,400,700" rel="stylesheet">

    <link rel="stylesheet" href="/assets/css/styles.css">
    <link rel="canonical" href="/pko-t5-dev-diary/">
    <link rel="alternate" type="application/rss+xml" title="PAUST TechBlog | Artificial Intelligent Tech Blog by PAUST" href="/feed.xml" />

    <!-- Include extra styles -->
    

    <!-- JavaScript enabled/disabled -->
    <script>
        document.querySelector('html').classList.remove('no-js');
    </script>
</head>

    <body class="has-push-menu">
        





        <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" display="none" version="1.1"><defs><symbol id="icon-menu" viewBox="0 0 1024 1024"><path class="path1" d="M128 213.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5zM128 725.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5zM128 469.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5z"/></symbol><symbol id="icon-search" viewBox="0 0 951 1024"><path class="path1" d="M658.286 475.429q0-105.714-75.143-180.857t-180.857-75.143-180.857 75.143-75.143 180.857 75.143 180.857 180.857 75.143 180.857-75.143 75.143-180.857zM950.857 950.857q0 29.714-21.714 51.429t-51.429 21.714q-30.857 0-51.429-21.714l-196-195.429q-102.286 70.857-228 70.857-81.714 0-156.286-31.714t-128.571-85.714-85.714-128.571-31.714-156.286 31.714-156.286 85.714-128.571 128.571-85.714 156.286-31.714 156.286 31.714 128.571 85.714 85.714 128.571 31.714 156.286q0 125.714-70.857 228l196 196q21.143 21.143 21.143 51.429z"/></symbol><symbol id="icon-close" viewBox="0 0 1000 1000"><path d="M969.8,870.3c27,27.7,27,71.8,0,99.1C955.7,983,937.9,990,920,990c-17.9,0-35.7-7-49.7-20.7L500,599L129.6,969.4C115.6,983,97.8,990,79.9,990s-35.7-7-49.7-20.7c-27-27.3-27-71.4,0-99.1L400.9,500L30.3,129.3c-27-27.3-27-71.4,0-99.1c27.3-27,71.8-27,99.4,0L500,400.9L870.4,30.2c27.7-27,71.8-27,99.4,0c27,27.7,27,71.8,0,99.1L599.1,500L969.8,870.3z"/></symbol><symbol id="icon-twitter" viewBox="0 0 951 1024"><path class="path1" d="M925.714 233.143q-38.286 56-92.571 95.429 0.571 8 0.571 24 0 74.286-21.714 148.286t-66 142-105.429 120.286-147.429 83.429-184.571 31.143q-154.857 0-283.429-82.857 20 2.286 44.571 2.286 128.571 0 229.143-78.857-60-1.143-107.429-36.857t-65.143-91.143q18.857 2.857 34.857 2.857 24.571 0 48.571-6.286-64-13.143-106-63.714t-42-117.429v-2.286q38.857 21.714 83.429 23.429-37.714-25.143-60-65.714t-22.286-88q0-50.286 25.143-93.143 69.143 85.143 168.286 136.286t212.286 56.857q-4.571-21.714-4.571-42.286 0-76.571 54-130.571t130.571-54q80 0 134.857 58.286 62.286-12 117.143-44.571-21.143 65.714-81.143 101.714 53.143-5.714 106.286-28.571z"/></symbol><symbol id="icon-facebook" viewBox="0 0 585 1024"><path class="path1" d="M548 6.857v150.857h-89.714q-49.143 0-66.286 20.571t-17.143 61.714v108h167.429l-22.286 169.143h-145.143v433.714h-174.857v-433.714h-145.714v-169.143h145.714v-124.571q0-106.286 59.429-164.857t158.286-58.571q84 0 130.286 6.857z"/></symbol><symbol id="icon-clock" viewBox="0 0 1000 1000"><path d="M500,10C229.8,10,10,229.8,10,500c0,270.2,219.8,490,490,490c270.2,0,490-219.8,490-490C990,229.8,770.2,10,500,10z M500,910.2c-226.2,0-410.2-184-410.2-410.2c0-226.2,184-410.2,410.2-410.2c226.2,0,410.2,184,410.2,410.2C910.2,726.1,726.2,910.2,500,910.2z M753.1,374c8.2,11.9,5.2,28.1-6.6,36.3L509.9,573.7c-4.4,3.1-9.6,4.6-14.8,4.6c-4.1,0-8.3-1-12.1-3c-8.6-4.5-14-13.4-14-23.1V202.5c0-14.4,11.7-26.1,26.1-26.1c14.4,0,26.1,11.7,26.1,26.1v300l195.6-135.1C728.7,359.2,744.9,362.1,753.1,374z"/></symbol><symbol id="icon-calendar" viewBox="0 0 1000 1000"><path d="M920,500v420H80V500H920 M990,430H10v490c0,38.7,31.3,70,70,70h840c38.7,0,70-31.3,70-70V430L990,430z"/><path d="M850,80v105c0,57.9-47.2,105-105,105c-58,0-105-47.1-105-105V80H360v105c0,57.9-47.2,105-105,105c-58,0-105-47.1-105-105V80C72.8,80,10,142.7,10,220v140h980V220C990,142.7,927.2,80,850,80z"/><path d="M255,10c-19.3,0-35,15.8-35,35v140c0,19.2,15.7,35,35,35c19.3,0,35-15.8,35-35V45C290,25.8,274.3,10,255,10z"/><path d="M745,10c-19.3,0-35,15.8-35,35v140c0,19.2,15.7,35,35,35c19.3,0,35-15.8,35-35V45C780,25.8,764.3,10,745,10z"/></symbol><symbol id="icon-github" viewBox="0 0 12 14"><path d="M6 1q1.633 0 3.012 0.805t2.184 2.184 0.805 3.012q0 1.961-1.145 3.527t-2.957 2.168q-0.211 0.039-0.312-0.055t-0.102-0.234q0-0.023 0.004-0.598t0.004-1.051q0-0.758-0.406-1.109 0.445-0.047 0.801-0.141t0.734-0.305 0.633-0.52 0.414-0.82 0.16-1.176q0-0.93-0.617-1.609 0.289-0.711-0.062-1.594-0.219-0.070-0.633 0.086t-0.719 0.344l-0.297 0.187q-0.727-0.203-1.5-0.203t-1.5 0.203q-0.125-0.086-0.332-0.211t-0.652-0.301-0.664-0.105q-0.352 0.883-0.062 1.594-0.617 0.68-0.617 1.609 0 0.664 0.16 1.172t0.41 0.82 0.629 0.523 0.734 0.305 0.801 0.141q-0.305 0.281-0.383 0.805-0.164 0.078-0.352 0.117t-0.445 0.039-0.512-0.168-0.434-0.488q-0.148-0.25-0.379-0.406t-0.387-0.187l-0.156-0.023q-0.164 0-0.227 0.035t-0.039 0.090 0.070 0.109 0.102 0.094l0.055 0.039q0.172 0.078 0.34 0.297t0.246 0.398l0.078 0.18q0.102 0.297 0.344 0.48t0.523 0.234 0.543 0.055 0.434-0.027l0.18-0.031q0 0.297 0.004 0.691t0.004 0.426q0 0.141-0.102 0.234t-0.312 0.055q-1.812-0.602-2.957-2.168t-1.145-3.527q0-1.633 0.805-3.012t2.184-2.184 3.012-0.805zM2.273 9.617q0.023-0.055-0.055-0.094-0.078-0.023-0.102 0.016-0.023 0.055 0.055 0.094 0.070 0.047 0.102-0.016zM2.516 9.883q0.055-0.039-0.016-0.125-0.078-0.070-0.125-0.023-0.055 0.039 0.016 0.125 0.078 0.078 0.125 0.023zM2.75 10.234q0.070-0.055 0-0.148-0.062-0.102-0.133-0.047-0.070 0.039 0 0.141t0.133 0.055zM3.078 10.562q0.062-0.062-0.031-0.148-0.094-0.094-0.156-0.023-0.070 0.062 0.031 0.148 0.094 0.094 0.156 0.023zM3.523 10.758q0.023-0.086-0.102-0.125-0.117-0.031-0.148 0.055t0.102 0.117q0.117 0.047 0.148-0.047zM4.016 10.797q0-0.102-0.133-0.086-0.125 0-0.125 0.086 0 0.102 0.133 0.086 0.125 0 0.125-0.086zM4.469 10.719q-0.016-0.086-0.141-0.070-0.125 0.023-0.109 0.117t0.141 0.062 0.109-0.109z"></path></symbol><symbol id="icon-medium" viewBox="0 0 1000 1000"><path d="M336.5,240.2v641.5c0,9.1-2.3,16.9-6.8,23.2s-11.2,9.6-20,9.6c-6.2,0-12.2-1.5-18-4.4L37.3,782.7c-7.7-3.6-14.1-9.8-19.4-18.3S10,747.4,10,739V115.5c0-7.3,1.8-13.5,5.5-18.6c3.6-5.1,8.9-7.7,15.9-7.7c5.1,0,13.1,2.7,24.1,8.2l279.5,140C335.9,238.6,336.5,239.5,336.5,240.2L336.5,240.2z M371.5,295.5l292,473.6l-292-145.5V295.5z M990,305.3v576.4c0,9.1-2.6,16.5-7.7,22.1c-5.1,5.7-12,8.5-20.8,8.5s-17.3-2.4-25.7-7.1L694.7,784.9L990,305.3z M988.4,239.7c0,1.1-46.8,77.6-140.3,229.4C754.6,621,699.8,709.8,683.8,735.7L470.5,389l177.2-288.2c6.2-10.2,15.7-15.3,28.4-15.3c5.1,0,9.8,1.1,14.2,3.3l295.9,147.7C987.6,237.1,988.4,238.2,988.4,239.7L988.4,239.7z"/></symbol><symbol id="icon-instagram" viewBox="0 0 489.84 489.84"><path d="M249.62,50.46c65.4,0,73.14.25,99,1.43C372.47,53,385.44,57,394.07,60.32a75.88,75.88,0,0,1,28.16,18.32,75.88,75.88,0,0,1,18.32,28.16c3.35,8.63,7.34,21.6,8.43,45.48,1.18,25.83,1.43,33.57,1.43,99s-0.25,73.14-1.43,99c-1.09,23.88-5.08,36.85-8.43,45.48a81.11,81.11,0,0,1-46.48,46.48c-8.63,3.35-21.6,7.34-45.48,8.43-25.82,1.18-33.57,1.43-99,1.43s-73.15-.25-99-1.43c-23.88-1.09-36.85-5.08-45.48-8.43A75.88,75.88,0,0,1,77,423.86,75.88,75.88,0,0,1,58.69,395.7c-3.35-8.63-7.34-21.6-8.43-45.48-1.18-25.83-1.43-33.57-1.43-99s0.25-73.14,1.43-99c1.09-23.88,5.08-36.85,8.43-45.48A75.88,75.88,0,0,1,77,78.64a75.88,75.88,0,0,1,28.16-18.32c8.63-3.35,21.6-7.34,45.48-8.43,25.83-1.18,33.57-1.43,99-1.43m0-44.13c-66.52,0-74.86.28-101,1.47s-43.87,5.33-59.45,11.38A120.06,120.06,0,0,0,45.81,47.44,120.06,120.06,0,0,0,17.56,90.82C11.5,106.4,7.36,124.2,6.17,150.27s-1.47,34.46-1.47,101,0.28,74.86,1.47,101,5.33,43.87,11.38,59.45a120.06,120.06,0,0,0,28.25,43.38,120.06,120.06,0,0,0,43.38,28.25c15.58,6.05,33.38,10.19,59.45,11.38s34.46,1.47,101,1.47,74.86-.28,101-1.47,43.87-5.33,59.45-11.38a125.24,125.24,0,0,0,71.63-71.63c6.05-15.58,10.19-33.38,11.38-59.45s1.47-34.46,1.47-101-0.28-74.86-1.47-101-5.33-43.87-11.38-59.45a120.06,120.06,0,0,0-28.25-43.38,120.06,120.06,0,0,0-43.38-28.25C394.47,13.13,376.67,9,350.6,7.8s-34.46-1.47-101-1.47h0Z" transform="translate(-4.7 -6.33)" /><path d="M249.62,125.48A125.77,125.77,0,1,0,375.39,251.25,125.77,125.77,0,0,0,249.62,125.48Zm0,207.41a81.64,81.64,0,1,1,81.64-81.64A81.64,81.64,0,0,1,249.62,332.89Z" transform="translate(-4.7 -6.33)"/><circle cx="375.66" cy="114.18" r="29.39" /></symbol><symbol id="icon-linkedin" viewBox="0 0 12 14"><path d="M2.727 4.883v7.742h-2.578v-7.742h2.578zM2.891 2.492q0.008 0.57-0.395 0.953t-1.059 0.383h-0.016q-0.641 0-1.031-0.383t-0.391-0.953q0-0.578 0.402-0.957t1.051-0.379 1.039 0.379 0.398 0.957zM12 8.187v4.437h-2.57v-4.141q0-0.82-0.316-1.285t-0.988-0.465q-0.492 0-0.824 0.27t-0.496 0.668q-0.086 0.234-0.086 0.633v4.32h-2.57q0.016-3.117 0.016-5.055t-0.008-2.313l-0.008-0.375h2.57v1.125h-0.016q0.156-0.25 0.32-0.438t0.441-0.406 0.68-0.34 0.895-0.121q1.336 0 2.148 0.887t0.813 2.598z"></path></symbol><symbol id="icon-heart" viewBox="0 0 34 30"><path d="M17,29.7 L16.4,29.2 C3.5,18.7 0,15 0,9 C0,4 4,0 9,0 C13.1,0 15.4,2.3 17,4.1 C18.6,2.3 20.9,0 25,0 C30,0 34,4 34,9 C34,15 30.5,18.7 17.6,29.2 L17,29.7 Z M9,2 C5.1,2 2,5.1 2,9 C2,14.1 5.2,17.5 17,27.1 C28.8,17.5 32,14.1 32,9 C32,5.1 28.9,2 25,2 C21.5,2 19.6,4.1 18.1,5.8 L17,7.1 L15.9,5.8 C14.4,4.1 12.5,2 9,2 Z" id="Shape"></path></symbol><symbol id="icon-arrow-right" viewBox="0 0 25.452 25.452"><path d="M4.471,24.929v-2.004l12.409-9.788c0.122-0.101,0.195-0.251,0.195-0.411c0-0.156-0.073-0.31-0.195-0.409L4.471,2.526V0.522c0-0.2,0.115-0.384,0.293-0.469c0.18-0.087,0.396-0.066,0.552,0.061l15.47,12.202c0.123,0.1,0.195,0.253,0.195,0.409c0,0.16-0.072,0.311-0.195,0.411L5.316,25.34c-0.155,0.125-0.372,0.147-0.552,0.061C4.586,25.315,4.471,25.13,4.471,24.929z"/></symbol><symbol id="icon-star" viewBox="0 0 48 48"><path fill="currentColor" d="M44,24c0,11.045-8.955,20-20,20S4,35.045,4,24S12.955,4,24,4S44,12.955,44,24z"/><path fill="#ffffff" d="M24,11l3.898,7.898l8.703,1.301l-6.301,6.102l1.5,8.699L24,30.898L16.199,35l1.5-8.699l-6.301-6.102  l8.703-1.301L24,11z"/></symbol><symbol id="icon-read" viewBox="0 0 32 32"><path fill="currentColor" d="M29,4H3C1.343,4,0,5.343,0,7v18c0,1.657,1.343,3,3,3h10c0,0.552,0.448,1,1,1h4c0.552,0,1-0.448,1-1h10  c1.657,0,3-1.343,3-3V7C32,5.343,30.657,4,29,4z M29,5v20H18.708c-0.618,0-1.236,0.146-1.789,0.422l-0.419,0.21V5H29z M15.5,5  v20.632l-0.419-0.21C14.528,25.146,13.91,25,13.292,25H3V5H15.5z M31,25c0,1.103-0.897,2-2,2H18v1h-4v-1H3c-1.103,0-2-0.897-2-2V7  c0-0.737,0.405-1.375,1-1.722V25c0,0.552,0.448,1,1,1h10.292c0.466,0,0.925,0.108,1.342,0.317l0.919,0.46  c0.141,0.07,0.294,0.106,0.447,0.106c0.153,0,0.306-0.035,0.447-0.106l0.919-0.46C17.783,26.108,18.242,26,18.708,26H29  c0.552,0,1-0.448,1-1V5.278C30.595,5.625,31,6.263,31,7V25z M6,12.5C6,12.224,6.224,12,6.5,12h5c0.276,0,0.5,0.224,0.5,0.5  S11.776,13,11.5,13h-5C6.224,13,6,12.776,6,12.5z M6,14.5C6,14.224,6.224,14,6.5,14h5c0.276,0,0.5,0.224,0.5,0.5S11.776,15,11.5,15  h-5C6.224,15,6,14.776,6,14.5z M6,16.5C6,16.224,6.224,16,6.5,16h5c0.276,0,0.5,0.224,0.5,0.5S11.776,17,11.5,17h-5  C6.224,17,6,16.776,6,16.5z M20,12.5c0-0.276,0.224-0.5,0.5-0.5h5c0.276,0,0.5,0.224,0.5,0.5S25.776,13,25.5,13h-5  C20.224,13,20,12.776,20,12.5z M20,14.5c0-0.276,0.224-0.5,0.5-0.5h5c0.276,0,0.5,0.224,0.5,0.5S25.776,15,25.5,15h-5  C20.224,15,20,14.776,20,14.5z M20,16.5c0-0.276,0.224-0.5,0.5-0.5h5c0.276,0,0.5,0.224,0.5,0.5S25.776,17,25.5,17h-5  C20.224,17,20,16.776,20,16.5z"></path></symbol></defs></svg>

        <header class="bar-header">
    <a id="menu" role="button">
        <svg id="open" class="icon-menu"><use xlink:href="#icon-menu"></use></svg>
    </a>
    <h1 class="logo">
        <a href="/">
            
                PAUST TechBlog <span class="version"></span>
            
        </a>
    </h1>
    <a id="search" class="dosearch" role="button">
        <svg class="icon-search"><use xlink:href="#icon-search"></use></svg>
    </a>
    
</header>

<div id="mask" class="overlay"></div>

<aside class="sidebar" id="sidebar">
    <nav id="navigation">
      <h2>Menu</h2>
      <ul>
  
    
      <li>
        <a href="/">Home</a>
      </li>
    
  
</ul>

    </nav>
</aside>

<div class="search-wrapper">
    <div class="search-form">
        <input type="text" class="search-field" placeholder="Search">
        <svg class="icon-remove-sign"><use xlink:href="#icon-close"></use></svg>
        <ul class="search-results search-list"></ul>
    </div>
</div>



        <section class="post one-column">
            <article role="article" class="post-content">
                <p class="post-info">
                    
                        <svg class="icon-calendar" id="date"><use xlink:href="#icon-calendar"></use></svg>
                        <time class="date" datetime="2022-08-24T20:21:00+09:00">
                            


August 24, 2022

                        </time>
                    
                    <svg id="clock" class="icon-clock"><use xlink:href="#icon-clock"></use></svg>
                    <span>9 min to read</span>
                </p>
                <h1 class="post-title">pko-T5 모델 개발기</h1>
                <p class="post-subtitle">파우스트에서 한국어 코퍼스를 활용하여 T5 를 개발했던 경험기</p>

                
                    <img src="https://s.abcnews.com/images/Technology/AP_black_hole_kab_150226_16x9_992.jpg" alt="Featured image" class="post-cover">
                

                <!-- Pagination links -->



                <!-- Add your table of contents here -->


                <h1 id="introduction">Introduction</h1>

<p>이번에 PAUST에서 한국어 기반 Open-domain QA 를 개발하였고 이를 T5로 쉽게 개발에 성공했습니다.</p>

<p>현재 Open-domain QA 를 만드는데에 있어 facebook 의 DPR 과 FiD를 활용하여 만드려고 하는 시도들이 많았습니다.</p>

<p>하지만 DPR 을 하기 위한 한국어 기반 사전학습모델은 <a href="https://huggingface.co/monologg/kobert">monologg/koBERT</a>, <a href="https://huggingface.co/klue/roberta-base">klue/roberta-base</a> 등이 있었지만 <a href="https://github.com/facebookresearch/FiD">FiD</a> 를 하는데에 있어서 encoder only 모델이 아닌 encoder-decoder 모델이 필요합니다.</p>

<p>encoder-decoder 모델에는 대표적으로 T5 와 BART 가 있습니다. PAUST 에서 한국어 기반의 encoder-decoder 모델을 활용해서 실험을 진행하는데 있어 아래 2가지의 조건이 필요했습니다.</p>

<ol>
  <li>BBPE 기반으로 tokenizer 를 만들어서 특수문자도 받을 수 있게 하자.</li>
  <li><a href="https://github.com/google-research/text-to-text-transfer-transformer/blob/main/released_checkpoints.md#t511">T5 v1.1</a>의 모델을 기반으로 하자.</li>
</ol>

<p>위 조건들을 충족시키고자 한국어 말뭉치와 transformers 라이브러리를 활용하여 T5 모델 학습에 도전해보았습니다.</p>

<p>tokenizers 라이브러리 덕분에 BBPE 는 쉽게 만들었지만, T5 모델 학습은 기존에는 tensorflow 로 구현 된 것을 저희가 쉽게 transformers 의 파이토치 모델을 활용하여 만들었습니다.</p>

<p>먼저, T5 는 Fig.1 에서 보듯이 text-to-text 라는 포맷으로 모든 데이터셋의 포맷을 통일합니다. 그렇기에 여러가지 NLP task 에도 적용이 가능하여 활용도가 매우 높은 모델입니다.</p>

<p><img src="https://1.bp.blogspot.com/-o4oiOExxq1s/Xk26XPC3haI/AAAAAAAAFU8/NBlvOWB84L0PTYy9TzZBaLf6fwPGJTR0QCLcBGAsYHQ/s1600/image3.gif" alt="FIg.1 Text-to-text 를 수행하는 T5 의 예시" /></p>

<p>FIg.1 Text-to-text 를 수행하는 T5 의 예시</p>

<p>이러한 점을 바탕으로 번역, 텍스트분류, 질의응답 등 여러가지 Task에 적용이 가능하며 응용 또한 무궁무진합니다.</p>

<p>이렇게 처음부터 사전학습을 만드는 것은 많은 GPU 리소스를 요구합니다. 저희 PAUST 같은 경우 한정된 GPU 리소스 상에서 여러가지 태스크를 학습해야했습니다. T5 모델 같은 경우 사전학습된 지식을 기반으로 미세한 튜닝(Fine-tuning) 만 하면 되었기에 이러한 점에서 회사에서 큰 장점으로 다가왔습니다.</p>

<p>참고로 T5 v1.1 은 T5 와 아래와 같은 다른 점은 <a href="https://github.com/google-research/text-to-text-transfer-transformer/blob/main/released_checkpoints.md#t511">링크</a>에 설명이 되어있습니다.</p>

<h1 id="implementation">Implementation</h1>

<p>처음에는 이걸 어떻게 만들까? 라는 생각을 했었습니다. 다행히도 모두의 말뭉치와 나무위키, 위키피디아 등등 실제로 쓸만한 한국어 데이터가 많았습니다. 그래서 봤더니 적어도 T5 v1.1 모델 같은 경우는 unsupervised learning 만 하면 되었기에 원래 논문에 있는 multitask-learning 은 배제하고 학습할 수 있어 편하게 진행할 수 있었습니다.</p>

<p>실제 학습의 시작은 <a href="https://github.com/huggingface/transformers">huggingface/transformers</a> 에서 예제로 제공해준 <a href="https://github.com/huggingface/transformers/blob/main/examples/flax/language-modeling/run_t5_mlm_flax.py">run_mlm_t5_flax.py</a> 에서 시작을 했지만 여기서 제공해주는건 정적으로 몇개의 비율로 T5의 span 을 만들어낼것인지 결정하기에 논문대로 랜덤하게 동적으로 마스킹을 하고 마스킹된 토큰들을 merge 하게끔 만들었습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">_fill_in_the_blank</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">words</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]):</span>
    <span class="s">"""
    input:
    {
      words: [My, name, is, T5, .]
    }
    output:
    {
      inputs: [&lt;extra_id_1&gt;, name, is, &lt;extra_id_2&gt;, .]
      outputs: [My, &lt;extra_id_1&gt;, T5, .]
    }
    """</span>
    <span class="n">mask_id</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

    <span class="n">min_prob</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">max_prob</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">2</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">copy</span><span class="p">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="n">words</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">)):</span>
        <span class="n">prob</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">random</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">min_prob</span> <span class="o">&lt;</span> <span class="n">prob</span> <span class="o">&lt;</span> <span class="n">max_prob</span><span class="p">:</span>
            <span class="n">inputs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">mask_id</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">targets</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">mask_id</span>

    <span class="k">def</span> <span class="nf">merge_mask</span><span class="p">(</span><span class="n">words_</span><span class="p">):</span>
        <span class="n">mask_spans</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">begin</span><span class="p">,</span> <span class="n">end</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">words_</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">w</span> <span class="o">==</span> <span class="n">mask_id</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">begin</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                    <span class="n">begin</span> <span class="o">=</span> <span class="n">i</span>
                <span class="n">end</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">end</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                    <span class="n">mask_spans</span><span class="p">.</span><span class="n">append</span><span class="p">((</span><span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">))</span>
                    <span class="n">begin</span><span class="p">,</span> <span class="n">end</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span>
        <span class="k">if</span> <span class="n">begin</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="n">end</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">mask_spans</span><span class="p">.</span><span class="n">append</span><span class="p">((</span><span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">))</span>

        <span class="n">new_words_</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">last_offset</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">mask_spans</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">extra_ids</span><span class="p">),</span> <span class="sa">f</span><span class="s">"mask_spans=</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">mask_spans</span><span class="p">)</span><span class="si">}</span><span class="s"> is over length of extra_ids"</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">mask_spans</span><span class="p">):</span>
            <span class="n">new_words_</span> <span class="o">+=</span> <span class="n">words_</span><span class="p">[</span><span class="n">last_offset</span><span class="p">:</span><span class="n">begin</span><span class="p">]</span>
            <span class="n">new_words_</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">extra_ids</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">last_offset</span> <span class="o">=</span> <span class="n">end</span>
        <span class="n">new_words_</span> <span class="o">+=</span> <span class="n">words_</span><span class="p">[</span><span class="n">last_offset</span><span class="p">:]</span>

        <span class="k">return</span> <span class="n">new_words_</span>

    <span class="n">inputs</span> <span class="o">=</span> <span class="n">merge_mask</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="n">merge_mask</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">{</span><span class="s">'inputs'</span><span class="p">:</span> <span class="n">inputs</span><span class="p">,</span> <span class="s">'targets'</span><span class="p">:</span> <span class="n">targets</span><span class="p">}</span>
</code></pre></div></div>

<p>위 코드에서 최소 1개의 token 이 mask 가 되게하되 최대 50%의 token 만 mask가 되게하면 적어도 한개의 mask 가 포함되기에 target 에서 전체가 mask가 되지 않게 할 수 있습니다.</p>

<p>이러한 작업을 T5 에서는 Span Corruption Task 라고 하며 아래와 같이 동작하게 됩니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">SpanCorruptionTask</span><span class="p">(</span><span class="n">tokens</span><span class="o">=</span><span class="p">[</span><span class="s">'My'</span><span class="p">,</span> <span class="s">'name'</span><span class="p">,</span> <span class="s">'is'</span><span class="p">,</span> <span class="s">'T5'</span><span class="p">,</span> <span class="s">'.'</span><span class="p">])</span> <span class="o">=&gt;</span> <span class="p">{</span>
  <span class="n">inputs</span><span class="p">:</span> <span class="p">[</span><span class="s">'&lt;extra_id_1&gt;'</span><span class="p">,</span> <span class="s">'name'</span><span class="p">,</span> <span class="s">'is'</span><span class="p">,</span> <span class="s">'&lt;extra_id_2&gt;'</span><span class="p">,</span> <span class="s">'.'</span><span class="p">]</span>
  <span class="n">outputs</span><span class="p">:</span> <span class="p">[</span><span class="s">'My'</span><span class="p">,</span> <span class="s">'&lt;extra_id_1&gt;'</span><span class="p">,</span> <span class="s">'T5'</span><span class="p">,</span> <span class="s">'.'</span><span class="p">]</span>
<span class="p">}</span>
</code></pre></div></div>

<p>학습환경은 pre-training 을 위해 A100 8장을 활용하여 학습을 진행했고 small/base/large 를 학습하는데 있어 각각 3일/16일/26일 정도가 소요되었습니다. 그리고 각 태스크의 Fine-tuning 을 위해 TPU v3-8 노드 한개에서 학습을 진행했습니다.</p>

<p>pre-training 을 위한 자세한 코드는 <a href="https://github.com/paust-team/pko-t5">https://github.com/paust-team/pko-t5</a> 에 올려두었습니다.</p>

<p>이렇게 만들어진 T5를 우리는 PAUST Korea T5를 줄여서 pko-t5라고 명명하였습니다. 이후에 이 학습 모델을 이용하여 다양한 실험을 진행하였는데 이와 관련한 자세한 내용은 다음 페이지(링크)에서 확인하실 수 있습니다.</p>

<h1 id="experiments">Experiments</h1>

<h2 id="nsmc">NSMC</h2>

<p>먼저 NSMC 데이터를 text-to-text 포맷으로 변환하여 실험해보았습니다. 실험 과정에 앞서 pko-t5 를 활용하여 아래와 같은 결과를 얻었습니다.</p>

<table>
  <thead>
    <tr>
      <th>Model name</th>
      <th>NSMC’s Accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>KoBART-base*</td>
      <td>90.24</td>
    </tr>
    <tr>
      <td>KETI-AIR/ke-t5-small-ko</td>
      <td>89.37</td>
    </tr>
    <tr>
      <td>KETI-AIR/ke-t5-base-ko</td>
      <td><strong>91.38</strong></td>
    </tr>
    <tr>
      <td>KETI-AIR/ke-t5-large-ko</td>
      <td>90.67</td>
    </tr>
    <tr>
      <td>paust/pko-t5-small</td>
      <td>89.54</td>
    </tr>
    <tr>
      <td>paust/pko-t5-base</td>
      <td>91.05</td>
    </tr>
    <tr>
      <td>paust/pko-t5-large</td>
      <td>91.15</td>
    </tr>
    <tr>
      <td>google/mt5-base</td>
      <td>87.63</td>
    </tr>
  </tbody>
</table>

<p>*: SKT 에서 발표한 <a href="https://github.com/SKT-AI/KoBART">KoBART-base</a> 에서 참고.</p>

<p>NSMC 에서 결과는 ke-t5 보다 살짝 떨어지지만 그래도 오차범위 내의 준수한 성능을 보여줍니다. NSMC 데이터를 가지고 학습을 할때는 text-to-text 의 성능을 위해서 기존에 encoder-only 아키텍처에서 하던 classification 이 아니라 document → label 을 generation 하도록 디자인했습니다.</p>

<p>예를 들면, 아래와 같은 문장에 대해서 BERT 스타일과 text-to-text 스타일은 각각 다르게 처리합니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Input</span><span class="p">:</span> <span class="s">"pko-t5 프로젝트는 정말 멋지고 훌륭하네요."</span>
<span class="n">BERT</span> <span class="n">label</span><span class="p">:</span> <span class="mi">1</span> <span class="p">(</span><span class="n">positive</span> <span class="n">label</span><span class="p">)</span>
<span class="n">T5</span> <span class="n">label</span><span class="p">:</span> <span class="s">"긍정적인 댓글"</span>
</code></pre></div></div>

<p>BERT와 같은 encoder-only 아키텍처는 사전학습이된 transformer block 의 weight 는 그대로 transfer learning 으로 활용할 수 있지만 마지막 classifier layer 는 새로 만들어야 합니다. 이유는 BERT 학습인 MaskedLM 과 classification 의 label 의 수가 다르기 때문입니다.</p>

<p>하지만, T5 는 label 을 자연어로 표현하여 text generation 으로 태스크를 해결하기 위해 text-to-text 라는 방법론을 제안하였습니다. 그 덕분에 T5는 사전학습에 사용했던 classifier layer 을 그대로 사용하게 됩니다. 이 점을 이용해서 multi-task learning 도 가능하며 여러가지 태스크에도 쉽게 적용할 수 있습니다.</p>

<h2 id="korquad-10-the-korean-question-answering-dataset"><a href="https://korquad.github.io/KorQuad%201.0/">KorQuAD 1.0 (<strong>The Korean Question Answering Dataset</strong>)</a></h2>

<p>이번 실험은 korquad 데이터셋을 통해 QA 에서 text-to-text 성능을 확인해보겠습니다. 물론 SOTA 에는 미치지 못하는 성능이지만 다른 T5 대비 어느정도의 pko-t5 가 어느정도의 성능 향상이 있는지 확인할 수 있었습니다.</p>

<p>T5는 QA 태스크에서도 BERT 스타일의 context 내에서 span을 찾기보다는 answer를 바로 생성하도록 학습합니다.</p>

<table>
  <thead>
    <tr>
      <th>Model name</th>
      <th>Exact-match</th>
      <th>F1-score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>pko-t5-base</td>
      <td>83.32</td>
      <td>88.30</td>
    </tr>
    <tr>
      <td>pko-t5-large</td>
      <td><strong>86.28</strong></td>
      <td><strong>91.22</strong></td>
    </tr>
    <tr>
      <td>mt5-large</td>
      <td>82.05</td>
      <td>88.20</td>
    </tr>
  </tbody>
</table>

<p>위는 korquad에서 T5의 학습 결과입니다.</p>

<p>korquad 에서도 어느정도 pko-t5 가 효과가 있었습니다. mt5-large 와 pko-t5-base 간의 성능이 비슷하고 이미 pko-t5-large 에서 mt5-large 보다 높은 성능을 기록했습니다.</p>

<p>저희는 이걸로 pko-t5 가 학습이 잘되었다고 판단하였고 KLUE 에 도전을 해보았습니다.</p>

<h2 id="kluekorean-language-understanding-evaluation"><a href="https://klue-benchmark.com/">KLUE(<strong>Korean Language Understanding Evaluation</strong>)</a></h2>

<p>아래 표는 KLUE 의 dev 셋을 가지고 평가한것입니다. Baseline 은 KLUE 논문에서 가장 성능이 좋다고 한 것을 가져왔습니다.</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>Model</th>
      <th>tc (macro F1)</th>
      <th>sts (pearsonr/F1)</th>
      <th>nli (acc)</th>
      <th>ner (entity-level F1)</th>
      <th>re (micro F1)</th>
      <th>dp (LAS)</th>
      <th>mrc (EM/F1)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td> </td>
      <td>Baseline</td>
      <td><strong>87.30</strong></td>
      <td><strong>93.20/86.13</strong></td>
      <td><strong>89.50</strong></td>
      <td>86.06</td>
      <td>71.06</td>
      <td>87.93</td>
      <td>75.26/ -</td>
    </tr>
    <tr>
      <td>FT</td>
      <td>pko-t5-smal</td>
      <td>86.21</td>
      <td>77.99/77.01</td>
      <td>69.20</td>
      <td>82.60</td>
      <td>62.95</td>
      <td>93.15</td>
      <td>43.81/46.58</td>
    </tr>
    <tr>
      <td>FT</td>
      <td>pko-t5-base</td>
      <td>87.29</td>
      <td>90.25/83.43</td>
      <td>79.73</td>
      <td>87.80</td>
      <td>72.94</td>
      <td>97.28</td>
      <td>61.53/64.74</td>
    </tr>
    <tr>
      <td>FT</td>
      <td>pko-t5-large</td>
      <td>87.12</td>
      <td>92.05/85.24</td>
      <td>84.96</td>
      <td><strong>88.18</strong></td>
      <td>72.26</td>
      <td><strong>97.60</strong></td>
      <td>68.01/71.44</td>
    </tr>
    <tr>
      <td>MT</td>
      <td>pko-t5-small</td>
      <td>85.85</td>
      <td>79.12/77.81</td>
      <td>66.8</td>
      <td>81.53</td>
      <td>67.93</td>
      <td>91.38</td>
      <td>44.97/48.07</td>
    </tr>
    <tr>
      <td>MT</td>
      <td>pko-t5-base</td>
      <td>86.86</td>
      <td>87.61/81.42</td>
      <td>75.46</td>
      <td>86.85</td>
      <td>71.85</td>
      <td>96.32</td>
      <td>61.95/65.06</td>
    </tr>
    <tr>
      <td>MT</td>
      <td>pko-t5-large</td>
      <td>87.25</td>
      <td>91.05/84.58</td>
      <td>82.16</td>
      <td>87.63</td>
      <td><strong>74.78</strong></td>
      <td>97.33</td>
      <td>69.18/71.92</td>
    </tr>
  </tbody>
</table>

<p>위 표에서 FT 는 단일 태스크 파인튜닝을 말하며, MT 는 멀티태스크 파인튜닝을 말합니다. 즉, MT 는 태스크들을 전부 text-to-text 포맷으로 바꾸어 학습을 진행하고 각 태스크 별로 성능 수치를 뽑았습니다.</p>

<p>TC, STS, NLI 는 기존 encoder 기반의 모델들이 더 잘하고 있었습니다. 이 부분은 text-to-text 로 학습했기에 T5 가 부족한걸로 보입니다. ㅠㅠ</p>

<p>하지만, NER, RE, DP 에 대해서는 encoder 기반 모델대비 훨씬 더 잘하는 모습을 보여줍니다. 저희가 예상하기로는 해당 태스크에 대해서 self-attention 만으로 동작하는 encoder 보다 cross-attention 을 기반으로 동작하는 encoder-decoder 모델이 더 효과적이라고 생각합니다.</p>

<p>여기서 MRC는 최대한 많은 context 를 담기 위해 question, context 를 포함하여 input 의 최대 길이를 1024 로 하여 학습했습니다. 그럼에도 불구하고, MRC 에 대해서는 현격히 낮은 성능을 보여줍니다. 이 부분에 대해서는 실험이 좀 더 필요해보였습니다.</p>

<h3 id="mrc에-대한-추가-실험-평가">MRC에 대한 추가 실험 평가</h3>

<table>
  <thead>
    <tr>
      <th>모델명</th>
      <th>(1) EM / F1</th>
      <th>(2) EM / F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>pko-t5-small</td>
      <td>42.20/45.03</td>
      <td>46.85/50.46</td>
    </tr>
    <tr>
      <td>pko-t5-base</td>
      <td>57.06/60.20</td>
      <td>63.12/67.38</td>
    </tr>
    <tr>
      <td>pko-t5-large</td>
      <td>61.53/64.94</td>
      <td>70.15/74.20</td>
    </tr>
  </tbody>
</table>

<ol>
  <li>max length를 512 로 하여 context 를 슬라이딩해서 학습</li>
  <li>context 이외에 title 을 포함하여 학습</li>
</ol>

<p>위 실험에서 봤을때 title 까지 포함하여 학습하였을 경우 좀 더 높아지는 양상을 보입니다.</p>

<p>현재 회사에서 pko-t5 는 어느정도 개발이 완료되어 FiD 를 위한 연구 및 개발에 착수했습니다. 이를 위해 pko-t5 를 from scratch 로 한국어에 대해 학습을 진행했는데요. 나름 괜찮은 모델이 나온거같아 아래와 같이 깃헙과 허깅페이스 리포를 공유합니다.</p>

<ul>
  <li>github: <a href="https://github.com/paust-team/pko-t5">https://github.com/paust-team/pko-t5</a></li>
  <li>huggingface: <a href="https://huggingface.co/paust/pko-t5-base">https://huggingface.co/paust/pko-t5-base</a></li>
</ul>

<p>이렇게 한국어 기반의 encoder-decoder 모델은 pko-t5 를 만들었는데요. 역시 만들고나니까 여러모로 쓸모가 있어서 회사에서는 꽤 많은 곳에 활용하고 있습니다.</p>

<p>여기까지 pko-t5 개발기를 공유드립니다. 끝까지 읽어주셔서 감사합니다.</p>

<h1 id="acknowledgement">Acknowledgement</h1>

<p>본 글은 <a href="https://sites.research.google/trc/about/">TPU Research Cloud Program</a>의 지원을 받아 진행한 연구자료입니다. TPU 를 무료로 사용할 수 있게 해준 Google TRC-Support 팀에 감사드립니다.</p>

<p>This article is supported by TPU Research Cloud Program. Let us thanks provide for free TPUs by the Google TRC-Support Team. Thank you.</p>


                <!-- Pagination links -->


            </article>

            

        </section>

        <!-- Add time bar only for pages without pagination -->
        

        <!-- Show modal if the post is the last one -->
        

        <!-- Show modal before user leaves the page -->
        

        <!-- Add your newsletter subscription form here -->

        <section class="share">
    <h3>Share</h3>
    <a aria-label="Share on Twitter" href="https://twitter.com/intent/tweet?text=&quot;파우스트에서 한국어 코퍼스를 활용하여 대규모 데이터셋과 pre-trained 모델로써 T5를 만들었던 개발 경험과 노하우를 공유합니다.&quot;%20/pko-t5-dev-diary/%20via%20&#64;&hashtags=modeling,shaple"
    onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;" title="Share on Twitter">
        <svg class="icon icon-twitter"><use xlink:href="#icon-twitter"></use></svg>
    </a>
    <a aria-label="Share on Facebook" href="https://www.facebook.com/sharer/sharer.php?u=/pko-t5-dev-diary/"
    onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;" title="Share on Facebook">
        <svg class="icon icon-facebook"><use xlink:href="#icon-facebook"></use></svg>
    </a>
</section>

        

  <section class="author">
    <div class="details">
      
        <img class="img-rounded" src="https://avatars.githubusercontent.com/u/44251210?s=400&u=b509971c0fe850f2154169f89f3eb2ffa059b918&v=4" alt="Dennis Park">
      
      <p class="def">Author</p>
      <h3 class="name">
        <a href="/authors/dennispark/">Dennis Park</a>
      </h3>
      <p class="desc">PAUST CTO</p>
      <p>
        
          <a href="https://github.com/1dennispark" title="Github">
            <svg><use xlink:href="#icon-github"></use></svg>
          </a>
        
        
        
        
        
        
      </p>
    </div>
  </section>

  
  
  
  
  
  
  

  <script type="application/ld+json">
  {
      "@context": "http://schema.org",
      "@type": "Person",
      "name": "Dennis Park",
      
      "image": "https://avatars.githubusercontent.com/u/44251210?s=400&u=b509971c0fe850f2154169f89f3eb2ffa059b918&v=4",
      
      "jobTitle": "Chief Technical Officer",
      "url": "/authors/dennispark/",
      "sameAs": [
        "https://github.com/1dennispark"
      ]
  }
  </script>


        

        <footer>
    <p>
      
        <a href="https://github.com/paust-team" title="Github">
          <svg><use xlink:href="#icon-github"></use></svg>
        </a>
      
      
      
      
      
      
    </p>

    <ul>
  
    
      <li>
        <a href="/">Home</a>
      </li>
    
  
</ul>


    <p>
      <span>Jekflix</span> was made with <svg class="love"><use xlink:href="#icon-heart"></use></svg> by <a href="https://rossener.com" target="_blank" class="creator">Thiago Rossener</a>
    </p>
</footer>









<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Organization",
  "name": "PAUST TechBlog",
  "description": "Artificial Intelligent Tech Blog by PAUST",
  "url": "/",
  "logo": {
      "@type": "ImageObject",
      "url": "/assets/img/icons/mediumtile.png",
      "width": "600",
      "height": "315"
  },
  "sameAs": [
    "https://github.com/paust-team"
  ]
}
</script>

<!-- Include the script that allows Netlify CMS login -->
<script src="https://identity.netlify.com/v1/netlify-identity-widget.js"></script>

<!-- Include the website scripts -->
<script src="/assets/js/scripts.min.js"></script>

<!-- Include Google Analytics script -->
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-XXXXXXXX-X"></script>
<script>
  var host = window.location.hostname;
  if (host != 'localhost') {
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-XXXXXXXX-X');
  }
</script>
  


<!-- Include extra scripts -->



        

        
        
        
        
        
        
        
        
        <script type="application/ld+json">
        {
            "@context": "http://schema.org",
            "@type": "BlogPosting",
            "name": "pko-T5 모델 개발기",
            "headline": "파우스트에서 한국어 코퍼스를 활용하여 T5 를 개발했던 경험기",
            "description": "파우스트에서 한국어 코퍼스를 활용하여 대규모 데이터셋과 pre-trained 모델로써 T5를 만들었던 개발 경험과 노하우를 공유합니다.",
            "image": "https://s.abcnews.com/images/Technology/AP_black_hole_kab_150226_16x9_992.jpg",
            "url": "/pko-t5-dev-diary/",
            "articleBody": "Introduction

이번에 PAUST에서 한국어 기반 Open-domain QA 를 개발하였고 이를 T5로 쉽게 개발에 성공했습니다.

현재 Open-domain QA 를 만드는데에 있어 facebook 의 DPR 과 FiD를 활용하여 만드려고 하는 시도들이 많았습니다.

하지만 DPR 을 하기 위한 한국어 기반 사전학습모델은 monologg/koBERT, klue/roberta-base 등이 있었지만 FiD 를 하는데에 있어서 encoder only 모델이 아닌 encoder-decoder 모델이 필요합니다.

encoder-decoder 모델에는 대표적으로 T5 와 BART 가 있습니다. PAUST 에서 한국어 기반의 encoder-decoder 모델을 활용해서 실험을 진행하는데 있어 아래 2가지의 조건이 필요했습니다.


  BBPE 기반으로 tokenizer 를 만들어서 특수문자도 받을 수 있게 하자.
  T5 v1.1의 모델을 기반으로 하자.


위 조건들을 충족시키고자 한국어 말뭉치와 transformers 라이브러리를 활용하여 T5 모델 학습에 도전해보았습니다.

tokenizers 라이브러리 덕분에 BBPE 는 쉽게 만들었지만, T5 모델 학습은 기존에는 tensorflow 로 구현 된 것을 저희가 쉽게 transformers 의 파이토치 모델을 활용하여 만들었습니다.

먼저, T5 는 Fig.1 에서 보듯이 text-to-text 라는 포맷으로 모든 데이터셋의 포맷을 통일합니다. 그렇기에 여러가지 NLP task 에도 적용이 가능하여 활용도가 매우 높은 모델입니다.



FIg.1 Text-to-text 를 수행하는 T5 의 예시

이러한 점을 바탕으로 번역, 텍스트분류, 질의응답 등 여러가지 Task에 적용이 가능하며 응용 또한 무궁무진합니다.

이렇게 처음부터 사전학습을 만드는 것은 많은 GPU 리소스를 요구합니다. 저희 PAUST 같은 경우 한정된 GPU 리소스 상에서 여러가지 태스크를 학습해야했습니다. T5 모델 같은 경우 사전학습된 지식을 기반으로 미세한 튜닝(Fine-tuning) 만 하면 되었기에 이러한 점에서 회사에서 큰 장점으로 다가왔습니다.

참고로 T5 v1.1 은 T5 와 아래와 같은 다른 점은 링크에 설명이 되어있습니다.

Implementation

처음에는 이걸 어떻게 만들까? 라는 생각을 했었습니다. 다행히도 모두의 말뭉치와 나무위키, 위키피디아 등등 실제로 쓸만한 한국어 데이터가 많았습니다. 그래서 봤더니 적어도 T5 v1.1 모델 같은 경우는 unsupervised learning 만 하면 되었기에 원래 논문에 있는 multitask-learning 은 배제하고 학습할 수 있어 편하게 진행할 수 있었습니다.

실제 학습의 시작은 huggingface/transformers 에서 예제로 제공해준 run_mlm_t5_flax.py 에서 시작을 했지만 여기서 제공해주는건 정적으로 몇개의 비율로 T5의 span 을 만들어낼것인지 결정하기에 논문대로 랜덤하게 동적으로 마스킹을 하고 마스킹된 토큰들을 merge 하게끔 만들었습니다.

def _fill_in_the_blank(self, words: List[int]):
    &quot;&quot;&quot;
    input:
    {
      words: [My, name, is, T5, .]
    }
    output:
    {
      inputs: [&amp;lt;extra_id_1&amp;gt;, name, is, &amp;lt;extra_id_2&amp;gt;, .]
      outputs: [My, &amp;lt;extra_id_1&amp;gt;, T5, .]
    }
    &quot;&quot;&quot;
    mask_id = -1

    min_prob = 1 / (len(words) + 1)
    max_prob = 1 / 2
    inputs = copy.deepcopy(words)
    targets = words
    for i in range(len(words)):
        prob = random.random()
        if min_prob &amp;lt; prob &amp;lt; max_prob:
            inputs[i] = mask_id
        else:
            targets[i] = mask_id

    def merge_mask(words_):
        mask_spans = []
        begin, end = None, None
        for i, w in enumerate(words_):
            if w == mask_id:
                if begin is None:
                    begin = i
                end = i + 1
            else:
                if end is not None:
                    mask_spans.append((begin, end))
                    begin, end = None, None
        if begin is not None and end is not None:
            mask_spans.append((begin, end))

        new_words_ = []
        last_offset = 0
        assert len(mask_spans) &amp;lt;= len(self.extra_ids), f&quot;mask_spans={len(mask_spans)} is over length of extra_ids&quot;
        for i, (begin, end) in enumerate(mask_spans):
            new_words_ += words_[last_offset:begin]
            new_words_.append(self.extra_ids[i])
            last_offset = end
        new_words_ += words_[last_offset:]

        return new_words_

    inputs = merge_mask(inputs)
    targets = merge_mask(targets)

    return {'inputs': inputs, 'targets': targets}


위 코드에서 최소 1개의 token 이 mask 가 되게하되 최대 50%의 token 만 mask가 되게하면 적어도 한개의 mask 가 포함되기에 target 에서 전체가 mask가 되지 않게 할 수 있습니다.

이러한 작업을 T5 에서는 Span Corruption Task 라고 하며 아래와 같이 동작하게 됩니다.

SpanCorruptionTask(tokens=['My', 'name', 'is', 'T5', '.']) =&amp;gt; {
  inputs: ['&amp;lt;extra_id_1&amp;gt;', 'name', 'is', '&amp;lt;extra_id_2&amp;gt;', '.']
  outputs: ['My', '&amp;lt;extra_id_1&amp;gt;', 'T5', '.']
}


학습환경은 pre-training 을 위해 A100 8장을 활용하여 학습을 진행했고 small/base/large 를 학습하는데 있어 각각 3일/16일/26일 정도가 소요되었습니다. 그리고 각 태스크의 Fine-tuning 을 위해 TPU v3-8 노드 한개에서 학습을 진행했습니다.

pre-training 을 위한 자세한 코드는 https://github.com/paust-team/pko-t5 에 올려두었습니다.

이렇게 만들어진 T5를 우리는 PAUST Korea T5를 줄여서 pko-t5라고 명명하였습니다. 이후에 이 학습 모델을 이용하여 다양한 실험을 진행하였는데 이와 관련한 자세한 내용은 다음 페이지(링크)에서 확인하실 수 있습니다.

Experiments

NSMC

먼저 NSMC 데이터를 text-to-text 포맷으로 변환하여 실험해보았습니다. 실험 과정에 앞서 pko-t5 를 활용하여 아래와 같은 결과를 얻었습니다.


  
    
      Model name
      NSMC’s Accuracy
    
  
  
    
      KoBART-base*
      90.24
    
    
      KETI-AIR/ke-t5-small-ko
      89.37
    
    
      KETI-AIR/ke-t5-base-ko
      91.38
    
    
      KETI-AIR/ke-t5-large-ko
      90.67
    
    
      paust/pko-t5-small
      89.54
    
    
      paust/pko-t5-base
      91.05
    
    
      paust/pko-t5-large
      91.15
    
    
      google/mt5-base
      87.63
    
  


*: SKT 에서 발표한 KoBART-base 에서 참고.

NSMC 에서 결과는 ke-t5 보다 살짝 떨어지지만 그래도 오차범위 내의 준수한 성능을 보여줍니다. NSMC 데이터를 가지고 학습을 할때는 text-to-text 의 성능을 위해서 기존에 encoder-only 아키텍처에서 하던 classification 이 아니라 document → label 을 generation 하도록 디자인했습니다.

예를 들면, 아래와 같은 문장에 대해서 BERT 스타일과 text-to-text 스타일은 각각 다르게 처리합니다.

Input: &quot;pko-t5 프로젝트는 정말 멋지고 훌륭하네요.&quot;
BERT label: 1 (positive label)
T5 label: &quot;긍정적인 댓글&quot;


BERT와 같은 encoder-only 아키텍처는 사전학습이된 transformer block 의 weight 는 그대로 transfer learning 으로 활용할 수 있지만 마지막 classifier layer 는 새로 만들어야 합니다. 이유는 BERT 학습인 MaskedLM 과 classification 의 label 의 수가 다르기 때문입니다.

하지만, T5 는 label 을 자연어로 표현하여 text generation 으로 태스크를 해결하기 위해 text-to-text 라는 방법론을 제안하였습니다. 그 덕분에 T5는 사전학습에 사용했던 classifier layer 을 그대로 사용하게 됩니다. 이 점을 이용해서 multi-task learning 도 가능하며 여러가지 태스크에도 쉽게 적용할 수 있습니다.

KorQuAD 1.0 (The Korean Question Answering Dataset)

이번 실험은 korquad 데이터셋을 통해 QA 에서 text-to-text 성능을 확인해보겠습니다. 물론 SOTA 에는 미치지 못하는 성능이지만 다른 T5 대비 어느정도의 pko-t5 가 어느정도의 성능 향상이 있는지 확인할 수 있었습니다.

T5는 QA 태스크에서도 BERT 스타일의 context 내에서 span을 찾기보다는 answer를 바로 생성하도록 학습합니다.


  
    
      Model name
      Exact-match
      F1-score
    
  
  
    
      pko-t5-base
      83.32
      88.30
    
    
      pko-t5-large
      86.28
      91.22
    
    
      mt5-large
      82.05
      88.20
    
  


위는 korquad에서 T5의 학습 결과입니다.

korquad 에서도 어느정도 pko-t5 가 효과가 있었습니다. mt5-large 와 pko-t5-base 간의 성능이 비슷하고 이미 pko-t5-large 에서 mt5-large 보다 높은 성능을 기록했습니다.

저희는 이걸로 pko-t5 가 학습이 잘되었다고 판단하였고 KLUE 에 도전을 해보았습니다.

KLUE(Korean Language Understanding Evaluation)

아래 표는 KLUE 의 dev 셋을 가지고 평가한것입니다. Baseline 은 KLUE 논문에서 가장 성능이 좋다고 한 것을 가져왔습니다.


  
    
       
      Model
      tc (macro F1)
      sts (pearsonr/F1)
      nli (acc)
      ner (entity-level F1)
      re (micro F1)
      dp (LAS)
      mrc (EM/F1)
    
  
  
    
       
      Baseline
      87.30
      93.20/86.13
      89.50
      86.06
      71.06
      87.93
      75.26/ -
    
    
      FT
      pko-t5-smal
      86.21
      77.99/77.01
      69.20
      82.60
      62.95
      93.15
      43.81/46.58
    
    
      FT
      pko-t5-base
      87.29
      90.25/83.43
      79.73
      87.80
      72.94
      97.28
      61.53/64.74
    
    
      FT
      pko-t5-large
      87.12
      92.05/85.24
      84.96
      88.18
      72.26
      97.60
      68.01/71.44
    
    
      MT
      pko-t5-small
      85.85
      79.12/77.81
      66.8
      81.53
      67.93
      91.38
      44.97/48.07
    
    
      MT
      pko-t5-base
      86.86
      87.61/81.42
      75.46
      86.85
      71.85
      96.32
      61.95/65.06
    
    
      MT
      pko-t5-large
      87.25
      91.05/84.58
      82.16
      87.63
      74.78
      97.33
      69.18/71.92
    
  


위 표에서 FT 는 단일 태스크 파인튜닝을 말하며, MT 는 멀티태스크 파인튜닝을 말합니다. 즉, MT 는 태스크들을 전부 text-to-text 포맷으로 바꾸어 학습을 진행하고 각 태스크 별로 성능 수치를 뽑았습니다.

TC, STS, NLI 는 기존 encoder 기반의 모델들이 더 잘하고 있었습니다. 이 부분은 text-to-text 로 학습했기에 T5 가 부족한걸로 보입니다. ㅠㅠ

하지만, NER, RE, DP 에 대해서는 encoder 기반 모델대비 훨씬 더 잘하는 모습을 보여줍니다. 저희가 예상하기로는 해당 태스크에 대해서 self-attention 만으로 동작하는 encoder 보다 cross-attention 을 기반으로 동작하는 encoder-decoder 모델이 더 효과적이라고 생각합니다.

여기서 MRC는 최대한 많은 context 를 담기 위해 question, context 를 포함하여 input 의 최대 길이를 1024 로 하여 학습했습니다. 그럼에도 불구하고, MRC 에 대해서는 현격히 낮은 성능을 보여줍니다. 이 부분에 대해서는 실험이 좀 더 필요해보였습니다.

MRC에 대한 추가 실험 평가


  
    
      모델명
      (1) EM / F1
      (2) EM / F1
    
  
  
    
      pko-t5-small
      42.20/45.03
      46.85/50.46
    
    
      pko-t5-base
      57.06/60.20
      63.12/67.38
    
    
      pko-t5-large
      61.53/64.94
      70.15/74.20
    
  



  max length를 512 로 하여 context 를 슬라이딩해서 학습
  context 이외에 title 을 포함하여 학습


위 실험에서 봤을때 title 까지 포함하여 학습하였을 경우 좀 더 높아지는 양상을 보입니다.

현재 회사에서 pko-t5 는 어느정도 개발이 완료되어 FiD 를 위한 연구 및 개발에 착수했습니다. 이를 위해 pko-t5 를 from scratch 로 한국어에 대해 학습을 진행했는데요. 나름 괜찮은 모델이 나온거같아 아래와 같이 깃헙과 허깅페이스 리포를 공유합니다.


  github: https://github.com/paust-team/pko-t5
  huggingface: https://huggingface.co/paust/pko-t5-base


이렇게 한국어 기반의 encoder-decoder 모델은 pko-t5 를 만들었는데요. 역시 만들고나니까 여러모로 쓸모가 있어서 회사에서는 꽤 많은 곳에 활용하고 있습니다.

여기까지 pko-t5 개발기를 공유드립니다. 끝까지 읽어주셔서 감사합니다.

Acknowledgement

본 글은 TPU Research Cloud Program의 지원을 받아 진행한 연구자료입니다. TPU 를 무료로 사용할 수 있게 해준 Google TRC-Support 팀에 감사드립니다.

This article is supported by TPU Research Cloud Program. Let us thanks provide for free TPUs by the Google TRC-Support Team. Thank you.
",
            "wordcount": "1704",
            "inLanguage": "ko",
            "dateCreated": "2022-08-24/",
            "datePublished": "2022-08-24/",
            "dateModified": "2022-08-24/",
            "author": {
                "@type": "Person",
                "name": "Dennis Park",
                
                "image": "https://avatars.githubusercontent.com/u/44251210?s=400&u=b509971c0fe850f2154169f89f3eb2ffa059b918&v=4",
                
                "jobTitle": "Chief Technical Officer",
                "url": "/authors/dennispark/",
                "sameAs": [
                    "https://github.com/1dennispark"
                ]
            },
            "publisher": {
                "@type": "Organization",
                "name": "PAUST TechBlog",
                "url": "/",
                "logo": {
                    "@type": "ImageObject",
                    "url": "/assets/img/blog-image.png",
                    "width": "600",
                    "height": "315"
                }
            },
            "mainEntityOfPage": "True",
            "genre": "blog",
            "articleSection": "blog",
            "keywords": ["modeling","shaple"]
        }
        </script>
    </body>
</html>
