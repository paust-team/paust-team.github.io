<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI:ers | Artificial Intelligent Tech Blog by PAUST</title>
    <description>Artificial Intelligent Tech Blog by PAUST</description>
    <link>/</link>
    <atom:link href="/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Thu, 25 Aug 2022 18:08:46 +0900</pubDate>
    <lastBuildDate>Thu, 25 Aug 2022 18:08:46 +0900</lastBuildDate>
    <generator>Jekyll v3.9.2</generator>
    
      <item>
        <title>pko-T5 모델 개발기</title>
        <description>&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt; &lt;p&gt;이번에 PAUST에서 한국어 기반 Open-domain QA 를 개발하였고 이를 T5로 쉽게 개발에 성공했습니다.&lt;/p&gt; &lt;p&gt;현재 Open-domain QA 를 만드는데에 있어 facebook 의 DPR 과 FiD를 활용하여 만드려고 하는 시도들이 많았습니다.&lt;/p&gt; &lt;p&gt;하지만 DPR 을 하기 위한 한국어 기반 사전학습모델은 &lt;a href=&quot;https://huggingface.co/monologg/kobert&quot;&gt;monologg/koBERT&lt;/a&gt;, &lt;a href=&quot;https://huggingface.co/klue/roberta-base&quot;&gt;klue/roberta-base&lt;/a&gt; 등이 있었지만 &lt;a href=&quot;https://github.com/facebookresearch/FiD&quot;&gt;FiD&lt;/a&gt; 를 하는데에 있어서 encoder only 모델이 아닌 encoder-decoder 모델이 필요합니다.&lt;/p&gt; &lt;p&gt;encoder-decoder 모델에는 대표적으로 T5 와 BART 가 있습니다. PAUST 에서 한국어 기반의 encoder-decoder 모델을 활용해서 실험을 진행하는데 있어 아래 2가지의 조건이 필요했습니다.&lt;/p&gt; &lt;ol&gt; &lt;li&gt;BBPE 기반으로 tokenizer 를 만들어서 특수문자도 받을 수 있게 하자.&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/google-research/text-to-text-transfer-transformer/blob/main/released_checkpoints.md#t511&quot;&gt;T5 v1.1&lt;/a&gt;의 모델을 기반으로 하자.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;위 조건들을 충족시키고자...</description>
        <pubDate>Wed, 24 Aug 2022 20:21:00 +0900</pubDate>
        <link>/pko-t5-dev-diary/</link>
        <guid isPermaLink="true">/pko-t5-dev-diary/</guid>
        
        <category>modeling</category>
        
        <category>shaple</category>
        
        <category>blog</category>
      </item>
    
  </channel>
</rss>
